{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global setting for figures\n",
    "options(repr.plot.width=10, repr.plot.height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R Demonstration - Polynomial Regression and Model Selection\n",
    "\n",
    "In this notebook we will study the `R` - Code used in week 7. It covers the material of the lecture notes starting at p. 203 (bottom) until the end of part II on p. 252. Again, the aim of this notebook is to explain the code snippets from an *coding* point of view and not so much from a statistical perspective. \n",
    "\n",
    "## Polynomial regression\n",
    "\n",
    "We start by loading the `Auto.csv` data and reproduce Example 7.4.13. We compute a linear regression model `mpg ~horsepower` and plot the model together with the data points. In the left plot the residual vs. fitted (predicted) plot is shown. This is the overloaded plot function of the `lm` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(1,2))\n",
    "Auto <- read.csv(\"Auto.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(mpg ~ horsepower, col=\"darkgrey\", ylab=\"Miles per gallon\", data=Auto, pch=20)\n",
    "grid()\n",
    "abline(lm(mpg ~ horsepower, data=Auto), col=\"blue\")\n",
    "plot(lm(mpg ~ horsepower, data=Auto), col=\"darkgrey\", which=1, pch=20)\n",
    "grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Auto)\n",
    "Auto$X <- NULL\n",
    "Auto$X1 <- NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compute a quadratic model for `mpg`. To this end, we again use the `lm`-function but this time we additionally insert the square of the horsepower value into the model. The `formula` class allows for powers (and other functions such as squareroots, logs, ...) by using the `I` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(lm(mpg ~ horsepower + I(1/horsepower), data=Auto))\n",
    "#summary(lm(mpg ~ horsepower + I(horsepower^2), data=Auto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the quadratic model and compare it to a fifth order model. Note that we explicitely compute the polynomial: We extract the coefficients from the model summary and compute the polynomial values for a fixed sequence of `x` values. (This code is not printed in the lecture notes, but the resulting figures are shown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum <- summary(lm(mpg ~ horsepower + I(horsepower^2), data=Auto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(1,2))\n",
    "\n",
    "#second order model\n",
    "plot(mpg ~ horsepower, col=\"darkgrey\", ylab=\"Miles per gallon\", xlim=c(50,220), data=Auto)\n",
    "b <- summary(lm(mpg ~ horsepower + I(horsepower^2), data=Auto))$coef[,1]\n",
    "x <- seq(50,250,1)\n",
    "lines(x, b[1] + b[2]*x + b[3]*x^2, col=\"blue\")\n",
    "\n",
    "#rational model\n",
    "plot(mpg ~ horsepower, col=\"darkgrey\", ylab=\"Miles per Gallon\", xlim=c(50,220), data=Auto)\n",
    "b <- lm(mpg ~ horsepower + I(1/horsepower), data=Auto)$coef\n",
    "x <- seq(50,250,1)\n",
    "lines(x, b[1] + b[2]*x + b[3]*1/x, col=\"darkgreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ANOVA is used to compare the quadratic and linear model. The syntax\n",
    "\n",
    "`anova(mod1, mod2)`\n",
    "\n",
    "performs an analysis of variance on the residuals of two models and tests the hypothesis, that there is no significant improvement by adding a quadratic term (it is therefore important that `mod1` and `mod2` are nested). A small p-value hence indicates that the hypothesis is abandoned and the quadratic term is important for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova(lm(mpg ~ horsepower, data=Auto), \n",
    "      lm(mpg ~ horsepower + I(1/horsepower), data=Auto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed with Example 7.4.14. We perform a linear model with and without an interaction term on the `Advertisment` data. We then plot the linear model. It is important to note that the `lm` function has an overloaded `plot` routine that produces five different figures when executed.  With the `which` parameter the number of the desired figure can be selected.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 7.9\n",
    "par(mfrow=c(1,2))\n",
    "Advertising <- read.csv(\"Advertising.csv\")\n",
    "plot(lm(sales ~ TV + radio, data=Advertising), which=1, col=\"darkgrey\")\n",
    "plot(lm(sales ~ TV + radio + TV*radio, data=Advertising), which=1, col=\"darkgrey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 7.10\n",
    "par(mfrow=c(1,2))\n",
    "Advertising <- read.csv(\"Advertising.csv\")\n",
    "plot(lm(sales ~ TV + radio, data=Advertising), which=3, col=\"darkgrey\")\n",
    "plot(lm(sales ~ TV + radio + TV*radio, data=Advertising), which=3, col=\"darkgrey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(lm(sales ~ TV + radio + TV*radio, data=Advertising))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 7.11\n",
    "par(mfrow=c(1,2))\n",
    "Advertising <- read.csv(\"Advertising.csv\")\n",
    "plot(lm(sales ~ TV + radio, data=Advertising), which=5, col=\"darkgrey\")\n",
    "plot(lm(sales ~ TV + radio + TV*radio, data=Advertising), which=5, col=\"darkgrey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Example 7.4.15. the problem of collinearity is studied.  We load the data and produce some standard scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(1,2))\n",
    "Credit <- read.csv(\"Credit.csv\")\n",
    "plot(Credit[,\"Limit\"], Credit[,\"Age\"], col=\"darkcyan\", xlab=\"Limit\", ylab=\"Age\")\n",
    "plot(Credit[,\"Limit\"], Credit[,\"Rating\"], col=\"darkcyan\", xlab=\"Limit\", ylab=\"Rating\")\n",
    "\n",
    "#pairs(Credit[,2:7],  pch=19, col = as.integer(Credit$Gender)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Examples 7.4.17 through 7.4.19 we quantify the correlation between the predictors. We use the `cor` function that computes a correlation matrix (the default setting is Pearson correlation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cor(Credit[,-c(1,8:11)]),digit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(corrplot)\n",
    "corrplot(cor(Credit[,-c(1,8:11)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside to the pairswise correlation, the multiple collinearity can be measured by performing linear models of each predictor on the other remaing predictors. From this model the *variance inflation factor (vif)* is computed. This function is implemented in the `car` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(car)\n",
    "vif(lm(Balance ~ Income + Age + Rating + Limit, data=Credit))\n",
    "summary(lm(Balance ~ Income + Age + Rating + Limit, data=Credit))$r.squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif(lm(Balance ~ Income + Age + Rating, data=Credit))\n",
    "summary(lm(Balance ~ Income + Age + Rating, data=Credit))$r.squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now collect all relevant steps for the marketing plan on p. 215. We put all functions into one block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data and compute a linear model\n",
    "Advertising <- read.csv(\"Advertising.csv\")\n",
    "summary(lm(sales ~ TV + radio + newspaper, data=Advertising))\n",
    "mean(Advertising$sales)\n",
    "\n",
    "# Compute confidence intervals for the coefficients\n",
    "round(confint(lm(sales ~ TV + radio + newspaper, data=Advertising)), digits=3)\n",
    "\n",
    "# Is there multiple collinearity in the data?\n",
    "round(vif(lm(sales ~ TV + radio + newspaper, data=Advertising)), digits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "We start with Example 8.2.1 (Forward selection). Here we use the `add1` function that adds each predictor separately predictor to an existing reference model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credit <- read.csv(\"Credit.csv\")\n",
    "Credit$X <- NULL\n",
    "head(Credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.full <- lm(Balance ~ ., data=Credit)\n",
    "f.empty <- lm(Balance ~ 1, data=Credit)\n",
    "sum <- summary(f.empty)\n",
    "sum$adj.r.squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add1(f.empty, scope=f.full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add more and more predictors to the model, where in each step the predictor with the lowest RSS is chosen. The `update` function updates the reference model by the variable indicated in the `formula` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.1 <- update(f.empty,.~.+Rating)\n",
    "summary(f.1)$r.squared\n",
    "add1(f.1,scope=f.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.2 <- update(f.1,.~.+Income)\n",
    "summary(f.2)$r.squared\n",
    "add1(f.2,scope=f.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(f.full)$r.squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credit.mod <- Credit\n",
    "Credit.mod$dummy <- rnorm(length(Credit$Balance))\n",
    "head(Credit.mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.full_dummy <- lm(Balance ~., data = Credit.mod)\n",
    "summary(f.full)$adj.r.squared\n",
    "summary(f.full_dummy)$adj.r.squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward model selection can be carried out at once with the `regsubsets` function in the `leaps` package. Startin from the simplest model (1) in each step on further variable is chosen and the respective indicator is set to `TRUE`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(leaps)\n",
    "reg <- regsubsets(Balance ~ ., data=Credit, method=\"forward\", nvmax=11)\n",
    "reg.sum <- summary(reg)\n",
    "reg.sum$which"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We move on to Example 8.2.2 which treats backward model selection. Here the idea is to start with the full model and then iteratively remove unimportant predictors. In `R` backward selection can be carried out step-by-step by means of the `drop1` function that removes the least important predictor from a given (rich) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.full <- lm(Balance ~ ., data=Credit)\n",
    "drop1(f.full, scope=f.full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that dropping `Education` yields the model with lowest `RSS` and hence we remove this predictor and proceed by applying `drop1` to the reduced model. Now `Married` is the least important predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.9 <- update(f.full, . ~ . -Education)\n",
    "drop1(f.9, scope=f.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, we can use `regsubsets` to perform backward model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg <- regsubsets(Balance ~. , data=Credit, method=\"backward\", nvmax=11)\n",
    "reg.sum <- summary(reg)\n",
    "reg.sum$which"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Example 8.2.3. we study the problem of overfitting in the context of multiple linear regression. We compute $R^2$ and adjusted $R^2$ values for the `Credit` data set and plot the repsective $R^2$ values against the number of predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg <- regsubsets(Balance ~ . , data=Credit, method=\"forward\", nvmax=11)\n",
    "reg.sum <- summary(reg)\n",
    "round(reg.sum$rsq, digits = 5)\n",
    "which.max(reg.sum$rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg <- regsubsets(Balance ~ . , data=Credit, method=\"forward\", nvmax=11)\n",
    "reg.sum <- summary(reg)\n",
    "round(reg.sum$adjr2,5)\n",
    "which.max(reg.sum$adjr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the regression models by forward selection\n",
    "reg <- regsubsets(Balance ~ ., data=Credit, method=\"forward\", nvmax=11)\n",
    "reg.sum <- summary(reg)\n",
    "\n",
    "#1-by-2 plot layout\n",
    "par(mfrow=c(1,3))\n",
    "#plot R^2 against number of predictors\n",
    "plot(reg.sum$rsq, type=\"l\", col=\"blue\", xlab=\"Number of Predictors\", ylab=expression(R^2))\n",
    "points(reg.sum$rsq, pch=20)\n",
    "#plot adjusted R^2 against number of predictors\n",
    "plot(reg.sum$adjr2, type=\"l\", col=\"blue\", xlab=\"Number of Predictors\", ylab=\"adjusted R squared\")\n",
    "points(reg.sum$adjr2, pch=20)\n",
    "#indicate the maximal value of adj. R^2\n",
    "points(which.max(reg.sum$adjr2), reg.sum$adjr2[which.max(reg.sum$adjr2)],col=\"red\",pch=2)\n",
    "\n",
    "#plot adjusted R^2 against number of predictors\n",
    "plot(reg.sum$cp, type=\"l\", col=\"blue\", xlab=\"Number of Predictors\", ylab=\"Mallows Cp\")\n",
    "points(reg.sum$cp, pch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Example 8.2.4 the Akaike model selection criterion is studied. The AIC can be used alternatively to the adjusted $R^2$. The following code snipped does the trick. Note that the summary of `regsubsets` contains only Mallow's $C_p$ value which is proportional to the AIC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg <- regsubsets(Balance ~ . , data=Credit, method=\"forward\", nvmax=11)\n",
    "reg.sum <- summary(reg)\n",
    "which.min(reg.sum$cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "stepAIC(f.full, trace = FALSE, direction = \"backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.sum$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `step` function does model selection by using the AIC criterion. The last output of the function is the final model. If the `trace` parameter is set to `0` then the intermediate models are hidden and only the final model is returned (default is `trace=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.full <- lm(Balance ~ ., data=Credit)\n",
    "f.empty <- lm(Balance ~ 1, data=Credit)\n",
    "step(f.empty, direction=\"forward\", scope=list(lower=f.empty, upper=f.full), trace = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Example 8.2.6 finally the BIC (Bayesian Information Criterion) is treated. The `regsubsets` object contains a variable called `bic` which contains the BIC for all submodels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.sum$bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the definition if AIC and BIC for the least squares problem:\n",
    "$$\n",
    "AIC = \\frac{1}{n\\hat\\sigma^2}\\left(\\text{RSS} + 2 p \\hat \\sigma^2 \\right) \\quad \\text{ and } \\quad \n",
    "BIC = \\frac{1}{n}\\left(\\text{RSS} + \\log(n) p \\hat \\sigma^2 \\right)\n",
    "$$\n",
    "These two quantities are almost proportional; the only difference being the weight in the penalty term\n",
    ": $2$ for the AIC and $\\log(n)$ for the BIC. The `step` function allows for customized regularization parameters by setting the `k` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.full <- lm(Balance ~ Income + Limit + Rating + Cards + Age + Education + Gender + Student + Married + Ethnicity, data=Credit)\n",
    "f.empty <- lm(Balance~NULL, data=Credit)\n",
    "step(f.empty, direction=\"forward\", scope=list(lower=f.empty, upper=f.full), trace=0, k=log(nrow(Credit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code snippet plots the AIC and BIC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the models. \n",
    "reg <- regsubsets(Balance ~ . , data=Credit, method=\"forward\", nvmax=11)\n",
    "reg.sum <- summary(reg)\n",
    "par(mfrow=c(1,2))\n",
    "# AIC plot\n",
    "plot(reg.sum$cp, type=\"l\", col=\"blue\", xlab=\"Number of Predictors\", ylab=\"cp (AIC)\")\n",
    "points(reg.sum$cp, pch=20)\n",
    "points(which.min(reg.sum$cp), reg.sum$cp[which.min(reg.sum$cp)],col=\"red\",pch=2)\n",
    "# BIC plot\n",
    "plot(reg.sum$bic, type=\"l\", col=\"blue\", xlab=\"Number of Predictors\", ylab=\"BIC\")\n",
    "points(reg.sum$bic, pch=20)\n",
    "points(which.min(reg.sum$bic), reg.sum$bic[which.min(reg.sum$bic)], col=\"red\",pch=2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
